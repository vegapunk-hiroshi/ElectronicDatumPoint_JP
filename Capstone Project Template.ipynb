{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered some data  : 基準点コード一覧.html\n"
     ]
    }
   ],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        print(\"Encountered a start tag:\", tag)\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        print(\"Encountered an end tag :\", tag)\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        print(\"Encountered some data  :\", data)\n",
    "\n",
    "parser = MyHTMLParser()\n",
    "parser.feed('基準点コード一覧.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (2.18.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.6/site-packages (4.6.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests) (2019.11.28)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install requests beautifulsoup4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd  \n",
    "\n",
    "\n",
    "url=\"https://terras.gsi.go.jp/observation_code.php\"\n",
    "\n",
    "# Make a GET request to fetch the raw HTML content\n",
    "html_content = requests.get(url).text\n",
    "\n",
    "# Parse the html content\n",
    "soup = BeautifulSoup(html_content, \"lxml\")\n",
    "csv = []\n",
    "for tr in soup.find_all(\"tr\"):\n",
    "    txt = tr.text.replace(\"\\n\", \",\")\n",
    "    txt = txt[2:]\n",
    "    txt = txt[:-1]\n",
    "    txt = txt.replace(\"     \", \" \")\n",
    "    txt = txt.replace(\"    \", \" \")\n",
    "    txt_list = txt.split(\",\")\n",
    "    csv.append(txt_list)\n",
    "    if tr.text == \"軌道追跡局\":\n",
    "        print(\"stop\")\n",
    "        break\n",
    "        \n",
    "csv = csv[1:]\n",
    "df = pd.DataFrame(csv)\n",
    "df.to_csv(\"GNSS-based_control_stations.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "電子基準点リストの分析\n",
    "- The outcome of this project can help analysing the GNSS-based control station datasets of Japan Government in varios viewpoints.\n",
    "- It requests an HTML and the program tabelize it.\n",
    "- You will know which prefecture have GNSS-based control station.\n",
    "\n",
    "ScanX autoclassfication Log\n",
    "- the data is the log of the usage of auto-classification process of point cloud in some SaaS service\n",
    "- We utilize this dataset to know more about the needs of the user towards to our core compitence\n",
    "- The solution which will be provided by the outcome from analysis will be having a clear priority and schedule of our feature development cycle in order to improve the quality of our core technology.\n",
    "\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "# Read in the data here\n",
    "# fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "fname = './Capstone/auto_classify_jobs_concatenated.csv'\n",
    "df = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>project_id</th>\n",
       "      <th>project_name</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "      <th>ground_profile</th>\n",
       "      <th>bt_class_profile</th>\n",
       "      <th>resolution</th>\n",
       "      <th>noise_profile</th>\n",
       "      <th>noise_type</th>\n",
       "      <th>...</th>\n",
       "      <th>ground_grndonly</th>\n",
       "      <th>class_grndonly</th>\n",
       "      <th>nextcore</th>\n",
       "      <th>switch_xy</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>email_encrypted</th>\n",
       "      <th>plan_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>638</td>\n",
       "      <td>Test after update 07/10</td>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wilderness</td>\n",
       "      <td>tight</td>\n",
       "      <td>mm</td>\n",
       "      <td>cm</td>\n",
       "      <td>remove_points</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-07-10 17:19:41</td>\n",
       "      <td>2020-07-10 17:20:25</td>\n",
       "      <td>00:00:44</td>\n",
       "      <td>71</td>\n",
       "      <td>X'80F2681A987ADF1E05E49512E3038B4465AA20E3615E...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>639</td>\n",
       "      <td>Auto Test 1</td>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nature</td>\n",
       "      <td>medium</td>\n",
       "      <td>mm</td>\n",
       "      <td>mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-07-10 17:25:30</td>\n",
       "      <td>2020-07-10 17:26:39</td>\n",
       "      <td>00:01:09</td>\n",
       "      <td>211</td>\n",
       "      <td>X'80E5841D618F62A2A8F9B85243097D127018C76C1095...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "      <td>Auto Classification Test TLS 700MB</td>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>town</td>\n",
       "      <td>medium</td>\n",
       "      <td>mm</td>\n",
       "      <td>mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-07-10 17:26:03</td>\n",
       "      <td>2020-07-10 21:40:04</td>\n",
       "      <td>04:14:01</td>\n",
       "      <td>31</td>\n",
       "      <td>X'800AE6800653E71293368F2124158FD38754A14497DB...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>641</td>\n",
       "      <td>Auto No Class Clean only</td>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>mm</td>\n",
       "      <td>classify</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-07-10 17:30:28</td>\n",
       "      <td>2020-07-10 17:31:04</td>\n",
       "      <td>00:00:36</td>\n",
       "      <td>211</td>\n",
       "      <td>X'80E5841D618F62A2A8F9B85243097D127018C76C1095...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>642</td>\n",
       "      <td>Auto Test Class no clean</td>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>town</td>\n",
       "      <td>loose</td>\n",
       "      <td>mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>remove_points</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-07-10 17:34:04</td>\n",
       "      <td>2020-07-10 17:35:01</td>\n",
       "      <td>00:00:57</td>\n",
       "      <td>211</td>\n",
       "      <td>X'80E5841D618F62A2A8F9B85243097D127018C76C1095...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id  project_id                        project_name        date summary  \\\n",
       "0       1         638             Test after update 07/10  2020-07-10     NaN   \n",
       "1       2         639                         Auto Test 1  2020-07-10     NaN   \n",
       "2       3         640  Auto Classification Test TLS 700MB  2020-07-10     NaN   \n",
       "3       4         641            Auto No Class Clean only  2020-07-10     NaN   \n",
       "4       5         642            Auto Test Class no clean  2020-07-10     NaN   \n",
       "\n",
       "  ground_profile bt_class_profile resolution noise_profile     noise_type  \\\n",
       "0     wilderness            tight         mm            cm  remove_points   \n",
       "1         nature           medium         mm            mm            NaN   \n",
       "2           town           medium         mm            mm            NaN   \n",
       "3            NaN              NaN         mm            mm       classify   \n",
       "4           town            loose         mm           NaN  remove_points   \n",
       "\n",
       "    ...     ground_grndonly  class_grndonly  nextcore  switch_xy  \\\n",
       "0   ...                   0               0         0          0   \n",
       "1   ...                   0               0         0          0   \n",
       "2   ...                   0               0         0          0   \n",
       "3   ...                   0               0         0          0   \n",
       "4   ...                   0               0         0          0   \n",
       "\n",
       "            created_at           updated_at upload_time user_id  \\\n",
       "0  2020-07-10 17:19:41  2020-07-10 17:20:25    00:00:44      71   \n",
       "1  2020-07-10 17:25:30  2020-07-10 17:26:39    00:01:09     211   \n",
       "2  2020-07-10 17:26:03  2020-07-10 21:40:04    04:14:01      31   \n",
       "3  2020-07-10 17:30:28  2020-07-10 17:31:04    00:00:36     211   \n",
       "4  2020-07-10 17:34:04  2020-07-10 17:35:01    00:00:57     211   \n",
       "\n",
       "                                     email_encrypted  plan_id  \n",
       "0  X'80F2681A987ADF1E05E49512E3038B4465AA20E3615E...        2  \n",
       "1  X'80E5841D618F62A2A8F9B85243097D127018C76C1095...        1  \n",
       "2  X'800AE6800653E71293368F2124158FD38754A14497DB...        2  \n",
       "3  X'80E5841D618F62A2A8F9B85243097D127018C76C1095...        1  \n",
       "4  X'80E5841D618F62A2A8F9B85243097D127018C76C1095...        1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "TODO\n",
    "1. Clean data\n",
    "2. construct airflow env\n",
    "2. learn docker\n",
    "2. start docker\n",
    "2. Create SQL code to create table in DB\n",
    "3. start airflow coding\n",
    "4. create load fact and dimensional data\n",
    "5. data check code\n",
    "6. set up aws service. redshift, s3, iam\n",
    "7. test env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "3.1\n",
    "The Fact table should be AutoClassificationLog as we want to know what kind of classification settings are frequently used and interest by users.\n",
    "The Dimensional table are user, project and time respectively to get insight from those viewpoint.\n",
    "\n",
    "3.2\n",
    "Load the data to staging table in redshift.\n",
    "Next, Transform and Extract and Load the fact and dimensional data from staging table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# TODO\n",
    "- sql queries for insertion \n",
    "- define each opera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
